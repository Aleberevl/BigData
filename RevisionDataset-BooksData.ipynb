{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bafe857f-db00-4cd6-a0dc-74bc2063e982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/27 19:57:37 WARN Utils: Your hostname, MacBook-Pro-de-Juan.local resolves to a loopback address: 127.0.0.1; using 192.168.100.16 instead (on interface en0)\n",
      "25/04/27 19:57:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/27 19:57:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de columnas: 10\n",
      "Número de registros: 212404\n",
      "\n",
      "Tipos de datos de cada columna:\n",
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- image: string (nullable = true)\n",
      " |-- previewLink: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- publishedDate: string (nullable = true)\n",
      " |-- infoLink: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- ratingsCount: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Número de registros con al menos un valor faltante: 158580\n",
      "\n",
      "Columnas con valores faltantes:\n",
      "- Title\n",
      "- description\n",
      "- authors\n",
      "- image\n",
      "- previewLink\n",
      "- publisher\n",
      "- publishedDate\n",
      "- infoLink\n",
      "- categories\n",
      "- ratingsCount\n",
      "\n",
      "--- Columna: Title ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: 212,403 (100.00%)\n",
      "Missing: 1 (0.00%)\n",
      "Unique values: 212,400\n",
      "Most Common: \"\"\"Mom (0.00%)\n",
      "Mismatched: 0 (0%)\n",
      "\n",
      "--- Columna: description ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: 144,047 (67.82%)\n",
      "Missing: 68,357 (32.18%)\n",
      "Unique values: 133,257\n",
      "Most Common: None (0.00%)\n",
      "Mismatched: 0 (0%)\n",
      "\n",
      "--- Columna: authors ---\n",
      "Valid: 181,153 (85.29%)\n",
      "Missing: 31,251 (14.71%)\n",
      "Unique values: 133,019\n",
      "Most Common: None (0.00%)\n",
      "Mismatched: 0 (0%)\n",
      "\n",
      "--- Columna: image ---\n",
      "Valid: 161,213 (75.90%)\n",
      "Missing: 51,191 (24.10%)\n",
      "Unique values: 149,421\n",
      "Most Common: None (0.00%)\n",
      "Mismatched: 0 (0%)\n",
      "\n",
      "--- Columna: previewLink ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: 188,349 (88.67%)\n",
      "Missing: 24,055 (11.33%)\n",
      "Unique values: 186,014\n",
      "Most Common: None (0.00%)\n",
      "Mismatched: 0 (0%)\n",
      "\n",
      "--- Columna: publisher ---\n",
      "Valid: 139,274 (65.57%)\n",
      "Missing: 73,130 (34.43%)\n",
      "Unique values: 34,265\n",
      "Most Common: None (0.00%)\n",
      "Mismatched: 0 (0%)\n",
      "\n",
      "--- Columna: publishedDate ---\n",
      "Valid: 186,560 (87.83%)\n",
      "Missing: 25,844 (12.17%)\n",
      "Unique values: 28,948\n",
      "Most Common: None (0.00%)\n",
      "Mismatched: 0 (0%)\n",
      "\n",
      "--- Columna: infoLink ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: 188,103 (88.56%)\n",
      "Missing: 24,301 (11.44%)\n",
      "Unique values: 180,644\n",
      "Most Common: None (0.00%)\n",
      "Mismatched: 0 (0%)\n",
      "\n",
      "--- Columna: categories ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: 171,880 (80.92%)\n",
      "Missing: 40,524 (19.08%)\n",
      "Unique values: 28,362\n",
      "Most Common: None (0.00%)\n",
      "Mismatched: 0 (0%)\n",
      "\n",
      "--- Columna: ratingsCount ---\n",
      "Valid: 63,852 (30.06%)\n",
      "Missing: 148,552 (69.94%)\n",
      "Unique values: 16,102\n",
      "Most Common: None (0.00%)\n",
      "Mismatched: 0 (0%)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------\n",
    "# Importar librerías necesarias\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, isnan, when, count, desc\n",
    "from pyspark.sql.types import DoubleType, FloatType, IntegerType, LongType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# -------------------------------------------\n",
    "# Crear sesión de Spark \n",
    "try:\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "except:\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Exploracion_Completa_Dataset\") \\\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"100\") \\\n",
    "        .config(\"spark.executor.memory\", \"4g\") \\\n",
    "        .config(\"spark.driver.memory\", \"4g\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# Cargar el dataset\n",
    "nombre_archivo = \"Books_data.csv\"  \n",
    "df = spark.read.csv(nombre_archivo, header=True, inferSchema=True)\n",
    "\n",
    "# Contar registros totales\n",
    "num_total = df.count()\n",
    "\n",
    "# -------------------------------------------\n",
    "# Estadísticas Generales del Dataset\n",
    "\n",
    "# Número de columnas\n",
    "num_columnas = len(df.columns)\n",
    "print(f\"Número de columnas: {num_columnas}\")\n",
    "\n",
    "# Número de registros\n",
    "print(f\"Número de registros: {num_total}\")\n",
    "\n",
    "# Tipos de datos de cada columna\n",
    "print(\"\\nTipos de datos de cada columna:\")\n",
    "df.printSchema()\n",
    "\n",
    "# Registros con al menos un valor faltante\n",
    "condiciones_nulos = [col(c).isNull() | (col(c) == \"\") for c in df.columns]\n",
    "df_nulos = df.withColumn(\"nulos\", sum([when(cond, 1).otherwise(0) for cond in condiciones_nulos]))\n",
    "total_registros_con_nulos = df_nulos.filter(col(\"nulos\") > 0).count()\n",
    "print(f\"\\nNúmero de registros con al menos un valor faltante: {total_registros_con_nulos}\")\n",
    "\n",
    "# Columnas con valores faltantes\n",
    "# Columnas numéricas\n",
    "numeric_columns = [field.name for field in df.schema.fields if isinstance(field.dataType, (DoubleType, FloatType))]\n",
    "\n",
    "# Conteo de nulos\n",
    "expressions = []\n",
    "for c in df.columns:\n",
    "    if c in numeric_columns:\n",
    "        expressions.append(count(when(col(c).isNull() | isnan(c), c)).alias(c))\n",
    "    else:\n",
    "        expressions.append(count(when(col(c).isNull() | (col(c) == \"\"), c)).alias(c))\n",
    "\n",
    "missing_counts = df.select(expressions).collect()[0].asDict()\n",
    "\n",
    "# Filtrar columnas con nulos\n",
    "columnas_con_faltantes = [columna for columna, nulos in missing_counts.items() if nulos > 0]\n",
    "\n",
    "print(\"\\nColumnas con valores faltantes:\")\n",
    "for columna in columnas_con_faltantes:\n",
    "    print(f\"- {columna}\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# Análisis detallado por columna\n",
    "def analizar_columna(df, columna, num_total):\n",
    "    print(f\"\\n--- Columna: {columna} ---\")\n",
    "    col_data = df.select(columna)\n",
    "    \n",
    "    # Valores nulos\n",
    "    if col_data.schema.fields[0].dataType in [DoubleType(), FloatType()]:\n",
    "        null_count = col_data.filter(col(columna).isNull() | isnan(col(columna))).count()\n",
    "    else:\n",
    "        null_count = col_data.filter(col(columna).isNull() | (col(columna) == \"\")).count()\n",
    "    \n",
    "    valid_count = num_total - null_count\n",
    "    percent_valid = (valid_count / num_total) * 100\n",
    "    percent_missing = (null_count / num_total) * 100\n",
    "    \n",
    "    # Valores únicos\n",
    "    unique_count = col_data.distinct().count()\n",
    "    \n",
    "    # Valor más común\n",
    "    most_common_row = col_data.groupBy(columna).count().orderBy(desc(\"count\")).first()\n",
    "    if most_common_row and most_common_row[0] is not None:\n",
    "        most_common_value = most_common_row[0]\n",
    "        most_common_percent = (most_common_row[1] / num_total) * 100\n",
    "    else:\n",
    "        most_common_value = None\n",
    "        most_common_percent = 0\n",
    "    \n",
    "    # Mostrar resultados básicos\n",
    "    print(f\"Valid: {valid_count:,} ({percent_valid:.2f}%)\")\n",
    "    print(f\"Missing: {null_count:,} ({percent_missing:.2f}%)\")\n",
    "    print(f\"Unique values: {unique_count:,}\")\n",
    "    print(f\"Most Common: {most_common_value} ({most_common_percent:.2f}%)\")\n",
    "    print(f\"Mismatched: 0 (0%)\")  # No hacemos validaciones externas\n",
    "\n",
    "    # Estadísticas para valores numericos \n",
    "    tipo = col_data.schema.fields[0].dataType\n",
    "    if isinstance(tipo, (DoubleType, FloatType, IntegerType, LongType)):\n",
    "        stats = col_data.describe().toPandas().set_index('summary')\n",
    "        print(\"\\nEstadísticas numéricas:\")\n",
    "        for metric in [\"mean\", \"stddev\", \"min\", \"max\"]:\n",
    "            value = stats.loc[metric, columna]\n",
    "            print(f\"{metric.capitalize()}: {value}\")\n",
    "\n",
    "        # Quartiles \n",
    "        approx = col_data.approxQuantile(columna, [0.25, 0.5, 0.75], 0.01)\n",
    "        print(f\"25%: {approx[0]}\")\n",
    "        print(f\"50% (Median): {approx[1]}\")\n",
    "        print(f\"75%: {approx[2]}\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# Aplicar análisis a todas las columnas\n",
    "for col_name in df.columns:\n",
    "    analizar_columna(df, col_name, num_total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae013980-2264-40bf-b42b-c01d63070f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-pyspark",
   "language": "python",
   "name": "env-pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
